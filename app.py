import os
import gradio as gr
import tempfile
import shutil
import soundfile as sf
from utils.whisper_utils import transcribe_audio, get_audio_duration
from core.inference import InferenceEngine

# åˆå§‹åŒ–æ¨ç†å¼•æ“ (Lazy Loadingï¼Œé€™è£¡åªæ˜¯å»ºç«‹å¯¦ä¾‹)
engine = InferenceEngine()

def save_temp_audio(original_path):
    """å°‡ä¸Šå‚³çš„éŸ³è¨Šå­˜ç‚ºæš«å­˜æª”"""
    suffix = os.path.splitext(original_path)[-1]
    if not suffix: suffix = ".wav"
    
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
        shutil.copy(original_path, tmp.name)
        return tmp.name

def check_audio_length(audio_path, min_sec=3, max_sec=10):
    """æª¢æŸ¥éŸ³è¨Šé•·åº¦æ˜¯å¦ç¬¦åˆè¦æ±‚"""
    duration = get_audio_duration(audio_path)
    if duration < min_sec:
        return False, f"èªéŸ³é•·åº¦åƒ… {duration:.1f} ç§’ï¼Œè«‹ä¸Šå‚³ 3â€“10 ç§’èªéŸ³ã€‚"
    if duration > max_sec:
        return False, f"èªéŸ³é•·åº¦ç‚º {duration:.1f} ç§’ï¼Œè«‹ä¸Šå‚³ 3â€“10 ç§’èªéŸ³ã€‚"
    return True, None

def process(reference_audio, inference_text):
    if reference_audio is None:
        return None, "è«‹ä¸Šå‚³èªéŸ³æ¨£æœ¬ã€‚"

    audio_path = save_temp_audio(reference_audio)
    
    try:
        # 1. æª¢æŸ¥é•·åº¦
        valid, msg = check_audio_length(audio_path)
        if not valid:
            return None, msg
            
        # 2. èªéŸ³è¾¨è­˜ (ASR)
        print(f"ğŸ¤ æ­£åœ¨è¾¨è­˜èªéŸ³: {audio_path}")
        prompt_text = transcribe_audio(audio_path)
        print(f"ğŸ“ è¾¨è­˜çµæœ: {prompt_text}")
        
        # 3. èªéŸ³åˆæˆ (TTS)
        print(f"ğŸ¤– é–‹å§‹åˆæˆèªéŸ³...")
        sr, audio_data = engine.synthesize(
            reference_audio_path=audio_path,
            prompt_text=prompt_text,
            inference_text=inference_text
        )
        
        # 4. å„²å­˜çµæœ
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
            out_wav_path = tmp.name
            
        sf.write(out_wav_path, audio_data, sr)
        print(f"âœ… åˆæˆæˆåŠŸï¼Œæª”æ¡ˆå·²å„²å­˜: {out_wav_path}")
        
        return out_wav_path, None
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return None, f"åˆæˆå¤±æ•—: {str(e)}"
    finally:
        # æ¸…ç†æš«å­˜æª”
        if os.path.exists(audio_path):
            try:
                os.remove(audio_path)
            except:
                pass

def ui():
    with gr.Blocks(title="GPT-SoVITS Voice Clone") as demo:
        gr.Markdown("# ğŸ™ï¸ ä¸­æ–‡èªéŸ³å…‹éš† (GPT-SoVITS v3)")
        gr.Markdown("è«‹ä¸Šå‚³ä¸€æ®µ 3â€“10 ç§’çš„ä¸­æ–‡èªéŸ³ä½œç‚ºåƒè€ƒï¼Œä¸¦è¼¸å…¥ä½ å¸Œæœ› AI èªªçš„è©±ã€‚")
        
        with gr.Row():
            with gr.Column():
                reference_audio = gr.Audio(
                    label="1. ä¸Šå‚³åƒè€ƒèªéŸ³ (3-10ç§’)", 
                    sources=["upload", "microphone"], 
                    type="filepath"
                )
                inference_text = gr.Textbox(
                    label="2. è¼¸å…¥ç›®æ¨™æ–‡å­— (ä¸­æ–‡)", 
                    placeholder="ä½ å¥½ï¼Œé€™æ˜¯ä¸€å€‹æ¸¬è©¦èªéŸ³ã€‚",
                    lines=3
                )
                run_btn = gr.Button("ğŸš€ é–‹å§‹èªéŸ³å…‹éš†", variant="primary")
            
            with gr.Column():
                output_audio = gr.Audio(label="åˆæˆçµæœ", type="filepath")
                status_msg = gr.Markdown("")

        def _wrapped(ref, text):
            audio_out, err_msg = process(ref, text)
            
            if audio_out is None:
                return None, f"âŒ {err_msg}"
            
            return audio_out, "âœ… åˆæˆå®Œæˆï¼"

        run_btn.click(
            _wrapped, 
            inputs=[reference_audio, inference_text], 
            outputs=[output_audio, status_msg]
        )
        
    return demo

if __name__ == "__main__":
    ui().launch()
